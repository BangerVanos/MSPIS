{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W(1) = [[1 2]] + 1 * [[1 1]] * 1 = [[1 2]]\n",
      "W(2) = [[1 2]] + 1 * [[ 1 -1]] * 0 = [[1 2]]\n",
      "W(3) = [[1 2]] + 1 * [[-1 -1]] * 0 = [[1 2]]\n",
      "W(4) = [[0 3]] + 1 * [[-1  1]] * 1 = [[0 3]]\n"
     ]
    }
   ],
   "source": [
    "# Task 1\n",
    "def activation(s):\n",
    "    return np.sign(1 + np.sign(s))[0, 0]\n",
    "\n",
    "w_start = np.matrix([0, 1])\n",
    "x = np.matrix([[1, 1], [1, -1], [-1, -1], [-1, 1]])\n",
    "alpha = 1\n",
    "w = w_start\n",
    "\n",
    "for i in range(4):\n",
    "    l = np.dot(w, x[i].T)\n",
    "    f = activation(l)    \n",
    "    w = w + alpha * x[i] * f\n",
    "    print(f'W({i + 1}) = {w} + {alpha} * {x[i]} * {f} = {w}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 0 ---\n",
      "[[-0.28102693]]\n"
     ]
    }
   ],
   "source": [
    "# Task 2 Backpropagation\n",
    "\n",
    "def activation(s):\n",
    "    return 1 / (1 + np.exp(-s))\n",
    "\n",
    "def derivative(a):\n",
    "    return np.multiply(a, 1 - a)\n",
    "    \n",
    "\n",
    "w1 = np.matrix([[-0.2, 0.1], [-0.1, 0.3]])\n",
    "t1 = np.matrix([-0.1, -0.1])\n",
    "\n",
    "w2 = np.matrix([0.2, 0.3])\n",
    "t2 = np.matrix([-0.2])\n",
    "\n",
    "x = np.matrix([0.1, 0.9])\n",
    "target = 0.9\n",
    "alpha = 0.25\n",
    "\n",
    "for epoch in range(1):\n",
    "    print(f'--- Epoch {epoch} ---')\n",
    "    z1 = np.matmul(x, w1.T)\n",
    "    o1 = activation(z1 - t1)\n",
    "    z2 = np.matmul(o1, w2.T)    \n",
    "    o2 = activation(z2 - t2)\n",
    "    error_der = o2 - target\n",
    "    \n",
    "    grad_w2 = np.multiply(o1, error_der * derivative(o2))       \n",
    "    grad_t2 = error_der * derivative(o2)            \n",
    "        \n",
    "    grad_hidden = np.multiply(derivative(o1), np.matmul(error_der * derivative(o2), w2))\n",
    "    grad_w1 = np.matmul(x.T, grad_hidden)\n",
    "    grad_t1 = grad_hidden\n",
    "    \n",
    "    w1 -= alpha * grad_w1\n",
    "    w2 -= alpha * grad_w2\n",
    "    t1 -= alpha * grad_t1\n",
    "    t2 -= alpha * grad_t2\n",
    "    print(error_der)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.28102693]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m delta2 \u001b[38;5;241m=\u001b[39m error \u001b[38;5;241m*\u001b[39m sigmoid_derivative(z2 \u001b[38;5;241m-\u001b[39m t2)\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Градиент на скрытом слое\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m delta1 \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmultiply(delta2 \u001b[38;5;241m*\u001b[39m w2, \u001b[43msigmoid_derivative\u001b[49m\u001b[43m(\u001b[49m\u001b[43mz1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mt1\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# Размерность delta1: (1, 2)\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# delta1 = np.multiply(delta2 * w2, sigmoid_derivative(z1 - t1))  # Размерность delta1: (1, 2)\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# Обновление весов и порогов\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Второй слой\u001b[39;00m\n\u001b[0;32m     47\u001b[0m delta_w2 \u001b[38;5;241m=\u001b[39m alpha \u001b[38;5;241m*\u001b[39m delta2 \u001b[38;5;241m*\u001b[39m a1  \u001b[38;5;66;03m# Размерность delta_w2: (1, 2)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[20], line 22\u001b[0m, in \u001b[0;36msigmoid_derivative\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msigmoid_derivative\u001b[39m(x):\n\u001b[0;32m     21\u001b[0m     s \u001b[38;5;241m=\u001b[39m sigmoid(x)\n\u001b[1;32m---> 22\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Programms\\Programming\\BSUIR\\MSPIS\\LW1_2\\.venv\\Lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:221\u001b[0m, in \u001b[0;36mmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, (N\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) :\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;66;03m# This promotes 1-D vectors to row vectors\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isscalar(other) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(other, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__rmul__\u001b[39m\u001b[38;5;124m'\u001b[39m) :\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m N\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m, other)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (1,2) and (1,2) not aligned: 2 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# ПЕРЕДЕЛАТЬ ПОД НОРМАЛЬНЫЕ РАЗМЕРНОСТИ\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Заданные параметры\n",
    "w1 = np.matrix([[-0.2, 0.1], [-0.1, 0.3]])\n",
    "t1 = np.matrix([-0.1, -0.1])\n",
    "\n",
    "w2 = np.matrix([[0.2, 0.3]])\n",
    "t2 = np.matrix([-0.2])\n",
    "\n",
    "x = np.matrix([0.1, 0.9])\n",
    "target = 0.9\n",
    "alpha = 0.25\n",
    "\n",
    "# Функции активации\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    s = sigmoid(x)\n",
    "    return s * (1 - s)\n",
    "\n",
    "# Прямой проход с измененной формулой активации\n",
    "# Первый слой\n",
    "z1 = x * w1.T  # Размерность z1: (1, 2)\n",
    "a1 = sigmoid(z1 - t1)  # Применяем сигмоиду с учетом порога\n",
    "\n",
    "# Второй слой (выходной слой)\n",
    "z2 = a1 * w2.T  # Размерность z2: (1, 1)\n",
    "y = sigmoid(z2 - t2)  # Выход сети с учетом порога\n",
    "\n",
    "# Ошибка\n",
    "error = target - y\n",
    "print(error)\n",
    "\n",
    "# Обратное распространение ошибки\n",
    "# Градиент на выходном слое\n",
    "delta2 = error * sigmoid_derivative(z2 - t2)\n",
    "\n",
    "# Градиент на скрытом слое\n",
    "delta1 = np.multiply(delta2 * w2, sigmoid_derivative(z1 - t1))  # Размерность delta1: (1, 2)\n",
    "# delta1 = np.multiply(delta2 * w2, sigmoid_derivative(z1 - t1))  # Размерность delta1: (1, 2)\n",
    "\n",
    "# Обновление весов и порогов\n",
    "# Второй слой\n",
    "delta_w2 = alpha * delta2 * a1  # Размерность delta_w2: (1, 2)\n",
    "delta_t2 = alpha * delta2\n",
    "\n",
    "# Первый слой\n",
    "delta_w1 = alpha * (delta1.T * x)  # Размерность delta_w1: (2, 2)\n",
    "delta_t1 = alpha * delta1\n",
    "\n",
    "# Вывод результатов\n",
    "print(\"Приращение весов первого слоя (delta_w1):\\n\", delta_w1)\n",
    "print(\"Приращение весов второго слоя (delta_w2):\\n\", delta_w2)\n",
    "print(\"Выход нейронной сети (y):\", y)\n",
    "print(\"Приращение порогов первого слоя (delta_t1):\", delta_t1)\n",
    "print(\"Приращение порогов второго слоя (delta_t2):\", delta_t2)\n",
    "print(\"Линейная ошибка нейронов на скрытом слое (delta1):\", delta1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Функция сигмоиды\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Производная сигмоиды\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Исходные данные\n",
    "w1 = np.matrix([[-0.2, 0.1], [-0.1, 0.3]])\n",
    "t1 = np.matrix([-0.1, -0.1])\n",
    "w2 = np.matrix([0.2, 0.3])\n",
    "t2 = np.matrix([-0.2])\n",
    "x = np.matrix([0.1, 0.9])\n",
    "target = 0.9\n",
    "alpha = 0.25\n",
    "\n",
    "# Прямое распространение\n",
    "# 1. Вычисляем синаптическое преобразование для скрытого слоя\n",
    "s1 = x * w1 + t1  # размер: 1x2\n",
    "# 2. Вычисляем выходы нейронов скрытого слоя\n",
    "y1 = sigmoid(s1)  # размер: 1x2\n",
    "# 3. Вычисляем синаптическое преобразование для выходного слоя\n",
    "s2 = y1 * w2.T + t2  # размер: 1x1\n",
    "# 4. Вычисляем выход сети\n",
    "y2 = sigmoid(s2)  # размер: 1x1\n",
    "\n",
    "# Обратное распространение\n",
    "# 1. Вычисляем ошибку на выходе\n",
    "error = target - y2\n",
    "# 2. Вычисляем локальный градиент выходного слоя\n",
    "delta2 = error * sigmoid_derivative(s2)\n",
    "# 3. Вычисляем локальный градиент скрытого слоя\n",
    "delta1 = np.multiply(w2 * delta2, sigmoid_derivative(s1))\n",
    "\n",
    "# Вычисляем приращения весов и порогов\n",
    "# 1. Приращение весов второго слоя\n",
    "dw2 = alpha * y1.T * delta2\n",
    "# 2. Приращение весов первого слоя\n",
    "dw1 = alpha * x.T * delta1\n",
    "# 3. Приращение порогов второго слоя\n",
    "dt2 = alpha * delta2\n",
    "# 4. Приращение порогов первого слоя\n",
    "dt1 = alpha * delta1\n",
    "# 5. Линейная ошибка нейронов скрытого слоя\n",
    "linear_error = np.array(w2 * delta2).flatten()\n",
    "\n",
    "print(f\"1. Приращение весов первого слоя:\\n{np.round(dw1, 3)}\")\n",
    "print(f\"2. Приращение весов второго слоя:\\n{np.round(dw2, 3)}\")\n",
    "print(f\"3. Выход нейронной сети:\\n{np.round(y2, 3)}\")\n",
    "print(f\"4. Приращение порогов первого слоя:\\n{np.round(dt1, 3)}\")\n",
    "print(f\"5. Приращение порогов второго слоя:\\n{np.round(dt2, 3)}\")\n",
    "print(f\"6. Линейная ошибка нейронов скрытого слоя:\\n{np.round(linear_error, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (2,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 37\u001b[0m\n\u001b[0;32m     34\u001b[0m delta2 \u001b[38;5;241m=\u001b[39m (o \u001b[38;5;241m-\u001b[39m target) \u001b[38;5;241m*\u001b[39m o \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m o)  \u001b[38;5;66;03m# Shape (1,1)  \u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# Delta for hidden neurons  \u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m delta1 \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mw2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdelta2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mh\u001b[49m \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m h)  \u001b[38;5;66;03m# Shape (2,1)  \u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;66;03m# Weight updates  \u001b[39;00m\n\u001b[0;32m     40\u001b[0m delta_w2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39malpha \u001b[38;5;241m*\u001b[39m h \u001b[38;5;241m*\u001b[39m delta2  \u001b[38;5;66;03m# Shape (2,1)  \u001b[39;00m\n",
      "File \u001b[1;32md:\\Programms\\Programming\\BSUIR\\MSPIS\\LW1_2\\.venv\\Lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:221\u001b[0m, in \u001b[0;36mmatrix.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, (N\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)) :\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;66;03m# This promotes 1-D vectors to row vectors\u001b[39;00m\n\u001b[1;32m--> 221\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masmatrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m isscalar(other) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(other, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__rmul__\u001b[39m\u001b[38;5;124m'\u001b[39m) :\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m N\u001b[38;5;241m.\u001b[39mdot(\u001b[38;5;28mself\u001b[39m, other)\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (2,1) and (2,1) not aligned: 1 (dim 1) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "\n",
    "# Sigmoid activation function  \n",
    "def sigmoid(z):  \n",
    "    return 1 / (1 + np.exp(-z))  \n",
    "\n",
    "# Given parameters  \n",
    "w1 = np.matrix([[-0.2, 0.1],   \n",
    "               [-0.1, 0.3]])  \n",
    "t1 = np.matrix([-0.1, -0.1]).T  # Shape (2,1)  \n",
    "\n",
    "w2 = np.matrix([[0.2],   \n",
    "               [0.3]])  # Shape (2,1)  \n",
    "t2 = np.matrix([-0.2])  # Shape (1,1)  \n",
    "\n",
    "x = np.matrix([0.1, 0.9]).T  # Shape (2,1)  \n",
    "target = 0.9  \n",
    "alpha = 0.25  \n",
    "\n",
    "# Forward Pass  \n",
    "# Hidden layer  \n",
    "a1 = -w1 @ x + t1  # Shape (2,1)  \n",
    "h = sigmoid(a1)     # Shape (2,1)  \n",
    "\n",
    "# Output layer  \n",
    "a2 = -w2.T @ h + t2  # Shape (1,1)  \n",
    "o = sigmoid(a2)       # Shape (1,1)  \n",
    "\n",
    "# Error (not used directly in backprop)  \n",
    "E = 0.5 * (target - o)**2  \n",
    "\n",
    "# Backward Pass  \n",
    "# Delta for output neuron  \n",
    "delta2 = (o - target) * o * (1 - o)  # Shape (1,1)  \n",
    "\n",
    "# Delta for hidden neurons  \n",
    "delta1 = (w2 @ delta2) * h * (1 - h)  # Shape (2,1)  \n",
    "\n",
    "# Weight updates  \n",
    "delta_w2 = -alpha * h * delta2  # Shape (2,1)  \n",
    "delta_w1 = -alpha * delta1 @ x.T  # Shape (2,2)  \n",
    "\n",
    "# Bias updates  \n",
    "delta_t2 = -alpha * delta2      # Scalar  \n",
    "delta_t1 = -alpha * delta1      # Shape (2,1)  \n",
    "\n",
    "# Compute Linear Errors for Hidden Neurons  \n",
    "linear_error_hidden = delta1  # Shape (2,1)  \n",
    "\n",
    "# Round results to 3 decimal places  \n",
    "delta_w1 = delta_w1.round(3)  \n",
    "delta_w2 = delta_w2.round(3)  \n",
    "o = o.round(3)  \n",
    "delta_t1 = delta_t1.round(3)  \n",
    "delta_t2 = delta_t2.round(3)  \n",
    "linear_error_hidden = linear_error_hidden.round(3)  \n",
    "\n",
    "# Display Results  \n",
    "print(\"1. Приращение весов первого слоя (delta_w1):\")  \n",
    "print(delta_w1)  \n",
    "print(\"\\n2. Приращение весов второго слоя (delta_w2):\")  \n",
    "print(delta_w2)  \n",
    "print(\"\\n3. Выход нейронной сети (Output o):\")  \n",
    "print(o)  \n",
    "print(\"\\n4. Приращение порогов первого слоя (delta_t1):\")  \n",
    "print(delta_t1)  \n",
    "print(\"\\n5. Приращение порогов второго слоя (delta_t2):\")  \n",
    "print(delta_t2)  \n",
    "print(\"\\n6. Линейная ошибка нейронов на скрытом слое (linear_error_hidden):\")  \n",
    "print(linear_error_hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
