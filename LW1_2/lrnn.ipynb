{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лабораторная работа 1 по дисциплине МРЗвИС\n",
    "# Выполнена студентом группы 121702\n",
    "# БГУИР Заломов Роман Андреевич\n",
    "#\n",
    "# Вариант 15: Реализовать модель линейной рециркуляционной сети \n",
    "# с постоянным коэффициентом обучения и нормированными весовыми коэффициентами.\n",
    "#\n",
    "# 21.10.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RGB_VALUE = 255\n",
    "COLOR_CHANNELS_AMOUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_blocks(image, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image.shape[:2]\n",
    "\n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "\n",
    "    blocks = []\n",
    "\n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i:i+b_h, j:j+b_w]                                  \n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i_h-b_h:i_h, j:j+b_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image[i:i+b_h, i_w-b_w:i_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image[i_h-b_h:i_h, i_w-b_w:i_w]\n",
    "        blocks.append(block)\n",
    "    \n",
    "    return np.asarray(blocks)\n",
    "\n",
    "\n",
    "def blocks_to_image(image_blocks, image_shape, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image_shape[:2]\n",
    "    c = image_shape[2] if len(image_shape) == 3 else 1\n",
    "\n",
    "    restored_image = np.zeros((i_h, i_w, c), dtype=np.float64)\n",
    "    count_matrix = np.zeros((i_h, i_w), dtype=np.float64)\n",
    "    \n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "    \n",
    "    block_index = 0\n",
    "    \n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]            \n",
    "            restored_image[i:i+b_h, j:j+b_w] += block\n",
    "            count_matrix[i:i+b_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i_h-b_h:i_h, j:j+b_w] += block\n",
    "            count_matrix[i_h-b_h:i_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i:i+b_h, i_w-b_w:i_w] += block\n",
    "            count_matrix[i:i+b_h, i_w-b_w:i_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image_blocks[block_index]\n",
    "        restored_image[i_h-b_h:i_h, i_w-b_w:i_w] += block\n",
    "        count_matrix[i_h-b_h:i_h, i_w-b_w:i_w] += 1    \n",
    "    \n",
    "    count_matrix[count_matrix == 0] = 1    \n",
    "    restored_image = restored_image / count_matrix[..., np.newaxis]    \n",
    "    \n",
    "    return restored_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(weights):\n",
    "    norms = np.linalg.norm(weights, axis=0)\n",
    "    return weights / norms\n",
    "\n",
    "# Функция активации\n",
    "def linear_activation(x):\n",
    "    return x\n",
    "\n",
    "class LRNN:\n",
    "    def __init__(self, input_dim, latent_dim, learning_rate=0.001):        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate        \n",
    "        \n",
    "        self.W_enc = normalize_weights(np.random.randn(self.input_dim, self.latent_dim))\n",
    "        self.W_dec = normalize_weights(np.random.randn(self.latent_dim, self.input_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = linear_activation(x @ self.W_enc)\n",
    "        x_reconstructed = linear_activation(z @ self.W_dec)\n",
    "        return z, x_reconstructed\n",
    "    \n",
    "    def backward(self, x, x_reconstructed):\n",
    "        error = x_reconstructed - x        \n",
    "        \n",
    "        dW_enc = (x.T @ error) @ self.W_dec.T\n",
    "        dW_dec = (x @ self.W_enc).T @ error               \n",
    "        \n",
    "        self.W_dec -= self.learning_rate * dW_dec\n",
    "        self.W_enc -= self.learning_rate * dW_enc        \n",
    "        \n",
    "        self.W_dec = normalize_weights(self.W_dec)\n",
    "        self.W_enc = normalize_weights(self.W_enc)\n",
    "    \n",
    "    def train(self, data, epochs=1000):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x in data:                \n",
    "                x = np.matrix(x)\n",
    "                _, x_reconstructed = self.forward(x)\n",
    "                self.backward(x, x_reconstructed)\n",
    "                total_loss += np.sum(np.array(x - x_reconstructed) ** 2)            \n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image compression/decompression pipeline\n",
    "def compress_image(compression_weights, img_array, channels_amount: int,\n",
    "                   block_height: int, block_width: int, overlap: float = 0):    \n",
    "    normalized = (2.0 * img_array.astype(np.float32) / MAX_RGB_VALUE) - 1.0\n",
    "    blocks = image_to_blocks(normalized, block_height, block_width, overlap)\n",
    "    blocks = blocks.reshape((len(blocks), block_height * block_width, channels_amount))\n",
    "    if channels_amount == 3:\n",
    "        blocks = blocks.transpose(0, 2, 1)    \n",
    "    blocks = np.einsum('ijk,kl->ijl', blocks, compression_weights)     \n",
    "    return blocks\n",
    "    \n",
    "\n",
    "def decompress_image(decompression_weights, compressed_img, img_shape, channels_amount: int,\n",
    "                     block_height: int, block_width: int, overlap: float = 0) -> Image.Image:\n",
    "    compressed_img = np.einsum('ijk,kl->ijl', compressed_img, decompression_weights)\n",
    "    compressed_img = MAX_RGB_VALUE * (compressed_img + 1.0) / 2.0\n",
    "    if channels_amount == 3:\n",
    "        compressed_img = compressed_img.transpose(0, 2, 1)\n",
    "    compressed_img = compressed_img.reshape((len(compressed_img), block_height, block_width, channels_amount))    \n",
    "    img_array = blocks_to_image(compressed_img, img_shape, block_height, block_width, overlap)    \n",
    "    return Image.fromarray(img_array).convert('RGB' if channels_amount == 3 else 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150, Loss: 3187.5566071141475\n",
      "Epoch 2/150, Loss: 1720.407918759288\n",
      "Epoch 3/150, Loss: 1437.9703036930896\n",
      "Epoch 4/150, Loss: 1259.6341368962035\n",
      "Epoch 5/150, Loss: 1136.2555528039948\n",
      "Epoch 6/150, Loss: 1046.9959711269817\n",
      "Epoch 7/150, Loss: 979.2503410078766\n",
      "Epoch 8/150, Loss: 925.2323071782897\n",
      "Epoch 9/150, Loss: 880.2672167046564\n",
      "Epoch 10/150, Loss: 841.5644703217059\n",
      "Epoch 11/150, Loss: 807.4270808913299\n",
      "Epoch 12/150, Loss: 776.7880306557604\n",
      "Epoch 13/150, Loss: 748.9478802943228\n",
      "Epoch 14/150, Loss: 723.426644357599\n",
      "Epoch 15/150, Loss: 699.8791396267354\n",
      "Epoch 16/150, Loss: 678.0457352824878\n",
      "Epoch 17/150, Loss: 657.7231229374584\n",
      "Epoch 18/150, Loss: 638.7465956032163\n",
      "Epoch 19/150, Loss: 620.9790497926989\n",
      "Epoch 20/150, Loss: 604.3039725291338\n",
      "Epoch 21/150, Loss: 588.6208218213752\n",
      "Epoch 22/150, Loss: 573.8418643597555\n",
      "Epoch 23/150, Loss: 559.8899153022081\n",
      "Epoch 24/150, Loss: 546.6966496768192\n",
      "Epoch 25/150, Loss: 534.2012882505171\n",
      "Epoch 26/150, Loss: 522.3495397953299\n",
      "Epoch 27/150, Loss: 511.0927282586939\n",
      "Epoch 28/150, Loss: 500.38706045250194\n",
      "Epoch 29/150, Loss: 490.19300545024925\n",
      "Epoch 30/150, Loss: 480.47476575963134\n",
      "Epoch 31/150, Loss: 471.1998254378009\n",
      "Epoch 32/150, Loss: 462.33856336019903\n",
      "Epoch 33/150, Loss: 453.86392182293497\n",
      "Epoch 34/150, Loss: 445.7511220856121\n",
      "Epoch 35/150, Loss: 437.977419616445\n",
      "Epoch 36/150, Loss: 430.5218928079935\n",
      "Epoch 37/150, Loss: 423.36525983779137\n",
      "Epoch 38/150, Loss: 416.4897191663039\n",
      "Epoch 39/150, Loss: 409.8788098950098\n",
      "Epoch 40/150, Loss: 403.5172888478078\n",
      "Epoch 41/150, Loss: 397.3910217895976\n",
      "Epoch 42/150, Loss: 391.486886660767\n",
      "Epoch 43/150, Loss: 385.7926870919883\n",
      "Epoch 44/150, Loss: 380.29707477929725\n",
      "Epoch 45/150, Loss: 374.9894795542136\n",
      "Epoch 46/150, Loss: 369.86004618767083\n",
      "Epoch 47/150, Loss: 364.8995771286997\n",
      "Epoch 48/150, Loss: 360.09948050726337\n",
      "Epoch 49/150, Loss: 355.4517228325447\n",
      "Epoch 50/150, Loss: 350.94878589891897\n",
      "Epoch 51/150, Loss: 346.58362747681525\n",
      "Epoch 52/150, Loss: 342.34964541820233\n",
      "Epoch 53/150, Loss: 338.2406448496142\n",
      "Epoch 54/150, Loss: 334.2508081616527\n",
      "Epoch 55/150, Loss: 330.3746675344029\n",
      "Epoch 56/150, Loss: 326.60707976448185\n",
      "Epoch 57/150, Loss: 322.9432031824056\n",
      "Epoch 58/150, Loss: 319.3784764692988\n",
      "Epoch 59/150, Loss: 315.9085992000479\n",
      "Epoch 60/150, Loss: 312.52951395641526\n",
      "Epoch 61/150, Loss: 309.23738986831484\n",
      "Epoch 62/150, Loss: 306.0286074548909\n",
      "Epoch 63/150, Loss: 302.8997446491939\n",
      "Epoch 64/150, Loss: 299.847563901302\n",
      "Epoch 65/150, Loss: 296.8690002647927\n",
      "Epoch 66/150, Loss: 293.9611503805719\n",
      "Epoch 67/150, Loss: 291.1212622803403\n",
      "Epoch 68/150, Loss: 288.34672593942355\n",
      "Epoch 69/150, Loss: 285.63506451547096\n",
      "Epoch 70/150, Loss: 282.98392621556906\n",
      "Epoch 71/150, Loss: 280.39107673982335\n",
      "Epoch 72/150, Loss: 277.8543922543429\n",
      "Epoch 73/150, Loss: 275.3718528510278\n",
      "Epoch 74/150, Loss: 272.94153645544947\n",
      "Epoch 75/150, Loss: 270.56161314773345\n",
      "Epoch 76/150, Loss: 268.23033986449053\n",
      "Epoch 77/150, Loss: 265.94605545270366\n",
      "Epoch 78/150, Loss: 263.7071760490429\n",
      "Epoch 79/150, Loss: 261.5121907603653\n",
      "Epoch 80/150, Loss: 259.3596576232094\n",
      "Epoch 81/150, Loss: 257.248199821974\n",
      "Epoch 82/150, Loss: 255.17650214709775\n",
      "Epoch 83/150, Loss: 253.14330767609994\n",
      "Epoch 84/150, Loss: 251.1474146616917\n",
      "Epoch 85/150, Loss: 249.18767361238795\n",
      "Epoch 86/150, Loss: 247.26298455219413\n",
      "Epoch 87/150, Loss: 245.3722944469608\n",
      "Epoch 88/150, Loss: 243.5145947859087\n",
      "Epoch 89/150, Loss: 241.68891930771596\n",
      "Epoch 90/150, Loss: 239.8943418613192\n",
      "Epoch 91/150, Loss: 238.1299743923104\n",
      "Epoch 92/150, Loss: 236.39496504646772\n",
      "Epoch 93/150, Loss: 234.68849638258416\n",
      "Epoch 94/150, Loss: 233.00978368731194\n",
      "Epoch 95/150, Loss: 231.35807338527394\n",
      "Epoch 96/150, Loss: 229.73264153816956\n",
      "Epoch 97/150, Loss: 228.13279242706852\n",
      "Epoch 98/150, Loss: 226.55785721248557\n",
      "Epoch 99/150, Loss: 225.00719266723337\n",
      "Epoch 100/150, Loss: 223.48017997740982\n",
      "Epoch 101/150, Loss: 221.9762236071943\n",
      "Epoch 102/150, Loss: 220.49475022346775\n",
      "Epoch 103/150, Loss: 219.03520767653234\n",
      "Epoch 104/150, Loss: 217.59706403348795\n",
      "Epoch 105/150, Loss: 216.17980666108187\n",
      "Epoch 106/150, Loss: 214.78294135504962\n",
      "Epoch 107/150, Loss: 213.40599151320188\n",
      "Epoch 108/150, Loss: 212.04849734971387\n",
      "Epoch 109/150, Loss: 210.71001514822257\n",
      "Epoch 110/150, Loss: 209.39011655155113\n",
      "Epoch 111/150, Loss: 208.08838788599942\n",
      "Epoch 112/150, Loss: 206.80442951829454\n",
      "Epoch 113/150, Loss: 205.53785524344087\n",
      "Epoch 114/150, Loss: 204.28829170180373\n",
      "Epoch 115/150, Loss: 203.0553778238959\n",
      "Epoch 116/150, Loss: 201.83876430143218\n",
      "Epoch 117/150, Loss: 200.63811308329866\n",
      "Epoch 118/150, Loss: 199.4530968951922\n",
      "Epoch 119/150, Loss: 198.28339878174313\n",
      "Epoch 120/150, Loss: 197.1287116700344\n",
      "Epoch 121/150, Loss: 195.98873795345207\n",
      "Epoch 122/150, Loss: 194.86318909492152\n",
      "Epoch 123/150, Loss: 193.75178524859155\n",
      "Epoch 124/150, Loss: 192.65425489910234\n",
      "Epoch 125/150, Loss: 191.57033451761933\n",
      "Epoch 126/150, Loss: 190.4997682338612\n",
      "Epoch 127/150, Loss: 189.44230752337066\n",
      "Epoch 128/150, Loss: 188.39771090934832\n",
      "Epoch 129/150, Loss: 187.36574367836945\n",
      "Epoch 130/150, Loss: 186.3461776093601\n",
      "Epoch 131/150, Loss: 185.33879071522784\n",
      "Epoch 132/150, Loss: 184.3433669965654\n",
      "Epoch 133/150, Loss: 183.35969620688863\n",
      "Epoch 134/150, Loss: 182.38757362887208\n",
      "Epoch 135/150, Loss: 181.42679986108345\n",
      "Epoch 136/150, Loss: 180.47718061473907\n",
      "Epoch 137/150, Loss: 179.5385265200103\n",
      "Epoch 138/150, Loss: 178.61065294144143\n",
      "Epoch 139/150, Loss: 177.69337980206248\n",
      "Epoch 140/150, Loss: 176.78653141577183\n",
      "Epoch 141/150, Loss: 175.88993632761634\n",
      "Epoch 142/150, Loss: 175.0034271615795\n",
      "Epoch 143/150, Loss: 174.12684047552975\n",
      "Epoch 144/150, Loss: 173.26001662297244\n",
      "Epoch 145/150, Loss: 172.40279962128199\n",
      "Epoch 146/150, Loss: 171.5550370260895\n",
      "Epoch 147/150, Loss: 170.71657981153402\n",
      "Epoch 148/150, Loss: 169.8872822560696\n",
      "Epoch 149/150, Loss: 169.06700183355807\n",
      "Epoch 150/150, Loss: 168.25559910938125\n"
     ]
    }
   ],
   "source": [
    "# Collecting everything\n",
    "\n",
    "block_width = 10\n",
    "block_height = 10\n",
    "\n",
    "img = Image.open('test_cat.jpg')\n",
    "img_array = np.asarray(img)\n",
    "shape = img_array.shape\n",
    "blocks = image_to_blocks(img_array, block_height, block_width, overlap=0)\n",
    "\n",
    "one_color = blocks[:, : ,:, 0]\n",
    "one_color = (2 * one_color / MAX_RGB_VALUE) - 1\n",
    "one_color = one_color.reshape((len(blocks), 10 * 10))\n",
    "\n",
    "train = np.matrix(one_color[np.random.choice(one_color.shape[0], int(one_color.shape[0] * 0.2))])\n",
    "train.shape\n",
    "train[0].shape\n",
    "\n",
    "network = LRNN(100, 64, 0.001)\n",
    "network.train(train, 150)\n",
    "\n",
    "compressed = compress_image(network.W_enc, img_array, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg = decompress_image(network.W_dec, compressed, shape, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg_array = np.asarray(dimg)\n",
    "dimg.save('compression-decompression_test.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
