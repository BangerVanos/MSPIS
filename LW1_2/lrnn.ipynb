{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лабораторная работа 1 по дисциплине МРЗвИС\n",
    "# Выполнена студентом группы 121702\n",
    "# БГУИР Заломов Роман Андреевич\n",
    "#\n",
    "# Вариант 15: Реализовать модель линейной рециркуляционной сети \n",
    "# с постоянным коэффициентом обучения и нормированными весовыми коэффициентами.\n",
    "#\n",
    "# 21.10.2024\n",
    "# 10.11.2024 Исправлена логика подсчёта ошибки и исправлена логика восстановления изображения из блоков\n",
    "# 21.11.2024 Исправлена логика подсчёта коэффициента сжатия\n",
    "# 24.11.2024 Исправлена логика подсчёта коэффициента сжатия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RGB_VALUE = 255\n",
    "COLOR_CHANNELS_AMOUNT = 3\n",
    "MAIN_FLOAT_TYPE = np.float16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_blocks(image, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image.shape[:2]\n",
    "\n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "\n",
    "    blocks = []\n",
    "\n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i:i+b_h, j:j+b_w]                                  \n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i_h-b_h:i_h, j:j+b_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image[i:i+b_h, i_w-b_w:i_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image[i_h-b_h:i_h, i_w-b_w:i_w]\n",
    "        blocks.append(block)\n",
    "    \n",
    "    return np.asarray(blocks)\n",
    "\n",
    "\n",
    "def blocks_to_image(image_blocks, image_shape, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image_shape[:2]\n",
    "    c = image_shape[2] if len(image_shape) == 3 else 1\n",
    "\n",
    "    restored_image = np.zeros((i_h, i_w, c), dtype=np.float64)\n",
    "    count_matrix = np.zeros((i_h, i_w), dtype=np.float64)\n",
    "    \n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "    \n",
    "    block_index = 0\n",
    "    \n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]            \n",
    "            restored_image[i:i+b_h, j:j+b_w] += block\n",
    "            count_matrix[i:i+b_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i_h-b_h:i_h, j:j+b_w] += block\n",
    "            count_matrix[i_h-b_h:i_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i:i+b_h, i_w-b_w:i_w] += block\n",
    "            count_matrix[i:i+b_h, i_w-b_w:i_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image_blocks[block_index]\n",
    "        restored_image[i_h-b_h:i_h, i_w-b_w:i_w] += block\n",
    "        count_matrix[i_h-b_h:i_h, i_w-b_w:i_w] += 1    \n",
    "    \n",
    "    count_matrix[count_matrix == 0] = 1    \n",
    "    restored_image = restored_image / count_matrix[..., np.newaxis]\n",
    "    restored_image[restored_image > 255] = 255    \n",
    "    \n",
    "    return restored_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(weights):\n",
    "    norms = np.linalg.norm(weights, axis=0)\n",
    "    return weights / norms\n",
    "\n",
    "# Функция активации\n",
    "def linear_activation(x):\n",
    "    return x\n",
    "\n",
    "class LRNN:\n",
    "    def __init__(self, input_dim, latent_dim, learning_rate=0.001):\n",
    "        np.random.seed(1)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate        \n",
    "        \n",
    "        self.W_enc = (normalize_weights(np.random.rand(self.input_dim, self.latent_dim))\n",
    "                      .astype(MAIN_FLOAT_TYPE))\n",
    "        self.W_dec = (normalize_weights(np.random.rand(self.latent_dim, self.input_dim))\n",
    "                      .astype(MAIN_FLOAT_TYPE))        \n",
    "\n",
    "        self.epoch: int = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = linear_activation(x @ self.W_enc)\n",
    "        x_reconstructed = linear_activation(z @ self.W_dec)\n",
    "        return z, x_reconstructed\n",
    "    \n",
    "    def backward(self, x, x_reconstructed):\n",
    "        error = x_reconstructed - x        \n",
    "        \n",
    "        dW_dec = (x @ self.W_enc).T @ error\n",
    "        dW_enc = (x.T @ error) @ self.W_dec.T                       \n",
    "        \n",
    "        self.W_dec -= self.learning_rate * dW_dec\n",
    "        self.W_enc -= self.learning_rate * dW_enc        \n",
    "        \n",
    "        self.W_dec = normalize_weights(self.W_dec)\n",
    "        self.W_enc = normalize_weights(self.W_enc)        \n",
    "    \n",
    "    def squared_error(self, y_true, y_predicted) -> float:\n",
    "        error = 0\n",
    "        y_true, y_predicted = np.array(y_true)[0], np.array(y_predicted)[0]\n",
    "        if len(y_true) != len(y_predicted):\n",
    "            raise ValueError('True and predicted vectors must be same size!')\n",
    "        for i in range(len(y_true)):\n",
    "            error += (y_true[i] - y_predicted[i]) * (y_true[i] - y_predicted[i])\n",
    "        return error\n",
    "    \n",
    "    def train(self, data, epochs=1000, max_loss: float = 100, learn_by_loss: bool = False):\n",
    "        for epoch in range(epochs):\n",
    "            self.epoch += 1\n",
    "            total_loss = 0\n",
    "            for x in data:                \n",
    "                x = np.matrix(x)\n",
    "                _, x_reconstructed = self.forward(x)\n",
    "                self.backward(x, x_reconstructed)\n",
    "            for x in data:\n",
    "                _, x_reconstructed = self.forward(x)\n",
    "                total_loss += self.squared_error(x, x_reconstructed)\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss}')                        \n",
    "            if learn_by_loss and total_loss <= max_loss:\n",
    "                break            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image compression/decompression pipeline\n",
    "def compress_image(compression_weights, img_array, channels_amount: int,\n",
    "                   block_height: int, block_width: int, overlap: float = 0):    \n",
    "    normalized = (2.0 * img_array.astype(MAIN_FLOAT_TYPE) / MAX_RGB_VALUE) - 1.0    \n",
    "    blocks = image_to_blocks(normalized, block_height, block_width, overlap)\n",
    "    blocks = blocks.reshape((len(blocks), block_height * block_width, channels_amount))\n",
    "    if channels_amount == 3:\n",
    "        blocks = blocks.transpose(0, 2, 1)    \n",
    "    blocks = np.einsum('ijk,kl->ijl', blocks, compression_weights)     \n",
    "    return blocks\n",
    "    \n",
    "\n",
    "def decompress_image(decompression_weights, compressed_img, img_shape, channels_amount: int,\n",
    "                     block_height: int, block_width: int, overlap: float = 0) -> Image.Image:\n",
    "    compressed_img = np.einsum('ijk,kl->ijl', compressed_img, decompression_weights)\n",
    "    compressed_img = MAX_RGB_VALUE * (compressed_img + 1.0) / 2.0\n",
    "    if channels_amount == 3:\n",
    "        compressed_img = compressed_img.transpose(0, 2, 1)\n",
    "    compressed_img = compressed_img.reshape((len(compressed_img), block_height, block_width, channels_amount))    \n",
    "    img_array = blocks_to_image(compressed_img, img_shape, block_height, block_width, overlap)    \n",
    "    return Image.fromarray(img_array).convert('RGB' if channels_amount == 3 else 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15000, Loss: 7996.492115596032\n",
      "Epoch 2/15000, Loss: 5466.891730898056\n",
      "Epoch 3/15000, Loss: 4889.23423671475\n",
      "Epoch 4/15000, Loss: 4555.97773912239\n",
      "Epoch 5/15000, Loss: 4330.3842542823495\n",
      "Epoch 6/15000, Loss: 4152.424401245242\n",
      "Epoch 7/15000, Loss: 4017.380836415817\n",
      "Epoch 8/15000, Loss: 3902.669337599564\n",
      "Epoch 9/15000, Loss: 3804.2766454414987\n",
      "Epoch 10/15000, Loss: 3720.6052414951355\n",
      "Epoch 11/15000, Loss: 3645.7080549723523\n",
      "Epoch 12/15000, Loss: 3578.5507968547226\n",
      "Epoch 13/15000, Loss: 3522.0347287703585\n",
      "Epoch 14/15000, Loss: 3472.198749294733\n",
      "Epoch 15/15000, Loss: 3426.4397006516015\n",
      "Epoch 16/15000, Loss: 3382.27502610465\n",
      "Epoch 17/15000, Loss: 3342.9296719894637\n",
      "Epoch 18/15000, Loss: 3306.611191750426\n",
      "Epoch 19/15000, Loss: 3272.5240156645827\n",
      "Epoch 20/15000, Loss: 3239.7221579029565\n",
      "Epoch 21/15000, Loss: 3210.0773399920013\n",
      "Epoch 22/15000, Loss: 3182.3263686397277\n",
      "Epoch 23/15000, Loss: 3155.5980149245092\n",
      "Epoch 24/15000, Loss: 3130.7866366020316\n",
      "Epoch 25/15000, Loss: 3107.472937008887\n",
      "Epoch 26/15000, Loss: 3085.3663836258092\n",
      "Epoch 27/15000, Loss: 3065.4004470102973\n",
      "Epoch 28/15000, Loss: 3047.4737751378507\n",
      "Epoch 29/15000, Loss: 3028.545172548374\n",
      "Epoch 30/15000, Loss: 3010.786209000618\n",
      "Epoch 31/15000, Loss: 2992.860608553462\n",
      "Epoch 32/15000, Loss: 2976.4522500654834\n",
      "Epoch 33/15000, Loss: 2959.8082913231015\n",
      "Epoch 34/15000, Loss: 2945.893679609969\n",
      "Epoch 35/15000, Loss: 2931.3821332258726\n",
      "Epoch 36/15000, Loss: 2916.92011211912\n",
      "Epoch 37/15000, Loss: 2904.8210044048074\n",
      "Epoch 38/15000, Loss: 2892.930670756697\n",
      "Epoch 39/15000, Loss: 2881.536179258067\n",
      "Epoch 40/15000, Loss: 2870.250658829419\n",
      "Epoch 41/15000, Loss: 2859.754054324788\n",
      "Epoch 42/15000, Loss: 2849.0537910398343\n",
      "Epoch 43/15000, Loss: 2839.062434053061\n",
      "Epoch 44/15000, Loss: 2828.1204674875944\n",
      "Epoch 45/15000, Loss: 2818.947839877758\n",
      "Epoch 46/15000, Loss: 2810.3504115136466\n",
      "Epoch 47/15000, Loss: 2801.168204770322\n",
      "Epoch 48/15000, Loss: 2792.641661105183\n",
      "Epoch 49/15000, Loss: 2784.9091638340765\n",
      "Epoch 50/15000, Loss: 2776.715439156196\n",
      "Epoch 51/15000, Loss: 2768.6963204542553\n",
      "Epoch 52/15000, Loss: 2761.1523408499265\n",
      "Epoch 53/15000, Loss: 2754.2168509932603\n",
      "Epoch 54/15000, Loss: 2747.523004396928\n",
      "Epoch 55/15000, Loss: 2740.8565200400326\n",
      "Epoch 56/15000, Loss: 2733.227378489649\n",
      "Epoch 57/15000, Loss: 2726.8151235416412\n",
      "Epoch 58/15000, Loss: 2720.1597361623108\n",
      "Epoch 59/15000, Loss: 2715.1165071114283\n",
      "Epoch 60/15000, Loss: 2707.8020976565554\n",
      "Epoch 61/15000, Loss: 2702.4097070150538\n",
      "Epoch 62/15000, Loss: 2696.947436779275\n",
      "Epoch 63/15000, Loss: 2692.2978786470526\n",
      "Epoch 64/15000, Loss: 2688.6226179985974\n",
      "Epoch 65/15000, Loss: 2684.0159277682833\n",
      "Epoch 66/15000, Loss: 2680.52393010185\n",
      "Epoch 67/15000, Loss: 2676.001732201036\n",
      "Epoch 68/15000, Loss: 2673.4480653625715\n",
      "Epoch 69/15000, Loss: 2668.994961962621\n",
      "Epoch 70/15000, Loss: 2664.8713800068113\n",
      "Epoch 71/15000, Loss: 2661.524299082241\n",
      "Epoch 72/15000, Loss: 2657.4603176163682\n",
      "Epoch 73/15000, Loss: 2653.790578248937\n",
      "Epoch 74/15000, Loss: 2651.0248238803124\n",
      "Epoch 75/15000, Loss: 2647.5215347741178\n",
      "Epoch 76/15000, Loss: 2644.076522246254\n",
      "Epoch 77/15000, Loss: 2640.3949440386496\n",
      "Epoch 78/15000, Loss: 2636.793318539921\n",
      "Epoch 79/15000, Loss: 2633.3470108182796\n",
      "Epoch 80/15000, Loss: 2629.8531870600964\n",
      "Epoch 81/15000, Loss: 2626.356867117206\n",
      "Epoch 82/15000, Loss: 2623.3201274798953\n",
      "Epoch 83/15000, Loss: 2620.4360724830635\n",
      "Epoch 84/15000, Loss: 2617.090727852273\n",
      "Epoch 85/15000, Loss: 2613.5809708129937\n",
      "Epoch 86/15000, Loss: 2610.4096326486347\n",
      "Epoch 87/15000, Loss: 2607.7982965367232\n",
      "Epoch 88/15000, Loss: 2603.6712988108957\n",
      "Epoch 89/15000, Loss: 2600.3053953353533\n",
      "Epoch 90/15000, Loss: 2597.295384977153\n",
      "Epoch 91/15000, Loss: 2593.729976753458\n",
      "Epoch 92/15000, Loss: 2590.921787665942\n",
      "Epoch 93/15000, Loss: 2587.721943517354\n",
      "Epoch 94/15000, Loss: 2584.211541304526\n",
      "Epoch 95/15000, Loss: 2581.2850945969135\n",
      "Epoch 96/15000, Loss: 2578.62121680177\n",
      "Epoch 97/15000, Loss: 2575.7814880112082\n",
      "Epoch 98/15000, Loss: 2572.857056100558\n",
      "Epoch 99/15000, Loss: 2570.428840188336\n",
      "Epoch 100/15000, Loss: 2567.516397882214\n",
      "Epoch 101/15000, Loss: 2564.634693660321\n",
      "Epoch 102/15000, Loss: 2561.9175978158123\n",
      "Epoch 103/15000, Loss: 2558.9054683891163\n",
      "Epoch 104/15000, Loss: 2557.2824082507623\n",
      "Epoch 105/15000, Loss: 2554.504255667624\n",
      "Epoch 106/15000, Loss: 2551.817192922574\n",
      "Epoch 107/15000, Loss: 2549.725699153666\n",
      "Epoch 108/15000, Loss: 2547.283981951237\n",
      "Epoch 109/15000, Loss: 2544.988242150574\n",
      "Epoch 110/15000, Loss: 2543.4112675871543\n",
      "Epoch 111/15000, Loss: 2541.2947696232754\n",
      "Epoch 112/15000, Loss: 2539.354996891464\n",
      "Epoch 113/15000, Loss: 2538.3765926836018\n",
      "Epoch 114/15000, Loss: 2536.4202441193925\n",
      "Epoch 115/15000, Loss: 2534.8364798403745\n",
      "Epoch 116/15000, Loss: 2533.493980756153\n",
      "Epoch 117/15000, Loss: 2531.6167370757935\n",
      "Epoch 118/15000, Loss: 2530.6468738036983\n",
      "Epoch 119/15000, Loss: 2530.0171873128097\n",
      "Epoch 120/15000, Loss: 2528.7856880312247\n",
      "Epoch 121/15000, Loss: 2527.0809671022485\n",
      "Epoch 122/15000, Loss: 2525.597608562152\n",
      "Epoch 123/15000, Loss: 2523.9975060551874\n",
      "Epoch 124/15000, Loss: 2522.7859094362416\n",
      "Epoch 125/15000, Loss: 2521.5087569461048\n",
      "Epoch 126/15000, Loss: 2519.7811891294295\n",
      "Epoch 127/15000, Loss: 2518.6556955292367\n",
      "Epoch 128/15000, Loss: 2517.4237579808687\n",
      "Epoch 129/15000, Loss: 2516.1270177890583\n",
      "Epoch 130/15000, Loss: 2515.147679947784\n",
      "Epoch 131/15000, Loss: 2513.2568722725855\n",
      "Epoch 132/15000, Loss: 2512.4128821495938\n",
      "Epoch 133/15000, Loss: 2510.5136617961193\n",
      "Epoch 134/15000, Loss: 2509.062173502167\n",
      "Epoch 135/15000, Loss: 2507.732826428611\n",
      "Epoch 136/15000, Loss: 2505.795624644912\n",
      "Epoch 137/15000, Loss: 2503.758944445887\n",
      "Epoch 138/15000, Loss: 2502.2340646361868\n",
      "Epoch 139/15000, Loss: 2500.1437460109196\n",
      "Epoch 140/15000, Loss: 2498.660343604196\n",
      "Compression coefficient: 1.2464201752511221\n",
      "Z = 2.478738189654073\n"
     ]
    }
   ],
   "source": [
    "# Collecting everything\n",
    "np.random.seed(1)\n",
    "\n",
    "block_width = 10\n",
    "block_height = 10\n",
    "\n",
    "n = block_height * block_width\n",
    "# Hidden layer neuron amount\n",
    "p = 40 \n",
    "\n",
    "img = Image.open('mountains.jpg')\n",
    "img_array = np.asarray(img)\n",
    "shape = img_array.shape\n",
    "blocks = image_to_blocks(img_array, block_height, block_width, overlap=0)\n",
    "\n",
    "l = len(blocks)\n",
    "# Compression coeff\n",
    "\n",
    "color_df = ((2 * blocks / MAX_RGB_VALUE) - 1).reshape(len(blocks), -1, 3).transpose(0, 2, 1).reshape(-1, n)\n",
    "train = np.matrix(color_df[np.random.choice(color_df.shape[0], int(color_df.shape[0] * 0.05))])\n",
    "\n",
    "\n",
    "network = LRNN(n, p, 0.001)\n",
    "network.train(train, 15000, learn_by_loss=True, max_loss=2500)\n",
    "\n",
    "compressed = compress_image(network.W_enc, img_array, COLOR_CHANNELS_AMOUNT, block_height, block_width, 0)\n",
    "\n",
    "compression_info_size = (\n",
    "    compressed.size * compressed.itemsize +\n",
    "    network.W_dec.size * network.W_dec.itemsize +\n",
    "    np.array(shape).size * np.array(shape).itemsize +\n",
    "    np.array((block_height, block_width)).size * np.array((block_height, block_width)).itemsize \n",
    ") * 8\n",
    "print(f'Compression coefficient: {(img_array.size * img_array.itemsize * 8) / compression_info_size}')\n",
    "print('Z =', (n*l) / ((n+l) * p + 2))\n",
    "\n",
    "dimg = decompress_image(network.W_dec, compressed, shape, COLOR_CHANNELS_AMOUNT, block_height, block_width, 0)\n",
    "dimg_array = np.asarray(dimg)\n",
    "\n",
    "dimg.save('compression-decompression_test.jpg')\n",
    "\n",
    "img_diff_array = np.minimum(np.abs(img_array - dimg_array), np.abs(dimg_array - img_array))\n",
    "img_diff = Image.fromarray(img_diff_array).convert('RGB')\n",
    "img_diff.save('compression-decompression_test_diff.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on another pic\n",
    "img = Image.open('mountains2.jpg')\n",
    "img_array = np.asarray(img)\n",
    "shape = img_array.shape\n",
    "compressed = compress_image(network.W_enc, img_array, COLOR_CHANNELS_AMOUNT, block_height, block_width, 0)\n",
    "dimg = decompress_image(network.W_dec, compressed, shape, COLOR_CHANNELS_AMOUNT, block_height, block_width, 0)\n",
    "dimg_array = np.asarray(dimg)\n",
    "dimg.save('compression-decompression_test2.jpg')\n",
    "\n",
    "img_diff_array = np.minimum(np.abs(img_array - dimg_array), np.abs(dimg_array - img_array))\n",
    "img_diff = Image.fromarray(img_diff_array).convert('RGB')\n",
    "img_diff.save('compression-decompression_test2_diff.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
