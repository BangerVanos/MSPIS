{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лабораторная работа 1 по дисциплине МРЗвИС\n",
    "# Выполнена студентом группы 121702\n",
    "# БГУИР Заломов Роман Андреевич\n",
    "#\n",
    "# Вариант 15: Реализовать модель линейной рециркуляционной сети \n",
    "# с постоянным коэффициентом обучения и нормированными весовыми коэффициентами.\n",
    "#\n",
    "# 21.10.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RGB_VALUE = 255\n",
    "COLOR_CHANNELS_AMOUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_blocks(image, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image.shape[:2]\n",
    "\n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "\n",
    "    blocks = []\n",
    "\n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i:i+b_h, j:j+b_w]                                  \n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i_h-b_h:i_h, j:j+b_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image[i:i+b_h, i_w-b_w:i_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image[i_h-b_h:i_h, i_w-b_w:i_w]\n",
    "        blocks.append(block)\n",
    "    \n",
    "    return np.asarray(blocks)\n",
    "\n",
    "\n",
    "def blocks_to_image(image_blocks, image_shape, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image_shape[:2]\n",
    "    c = image_shape[2] if len(image_shape) == 3 else 1\n",
    "\n",
    "    restored_image = np.zeros((i_h, i_w, c), dtype=np.float64)\n",
    "    count_matrix = np.zeros((i_h, i_w), dtype=np.float64)\n",
    "    \n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "    \n",
    "    block_index = 0\n",
    "    \n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]            \n",
    "            restored_image[i:i+b_h, j:j+b_w] += block\n",
    "            count_matrix[i:i+b_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i_h-b_h:i_h, j:j+b_w] += block\n",
    "            count_matrix[i_h-b_h:i_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i:i+b_h, i_w-b_w:i_w] += block\n",
    "            count_matrix[i:i+b_h, i_w-b_w:i_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image_blocks[block_index]\n",
    "        restored_image[i_h-b_h:i_h, i_w-b_w:i_w] += block\n",
    "        count_matrix[i_h-b_h:i_h, i_w-b_w:i_w] += 1    \n",
    "    \n",
    "    count_matrix[count_matrix == 0] = 1    \n",
    "    restored_image = restored_image / count_matrix[..., np.newaxis]    \n",
    "    \n",
    "    return restored_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(weights):\n",
    "    norms = np.linalg.norm(weights, axis=0)\n",
    "    return weights / norms\n",
    "\n",
    "# Функция активации\n",
    "def linear_activation(x):\n",
    "    return x\n",
    "\n",
    "class LRNN:\n",
    "    def __init__(self, input_dim, latent_dim, learning_rate=0.001):        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate        \n",
    "        \n",
    "        self.W_enc = normalize_weights(np.random.rand(self.input_dim, self.latent_dim))\n",
    "        self.W_dec = normalize_weights(np.random.rand(self.latent_dim, self.input_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = linear_activation(x @ self.W_enc)\n",
    "        x_reconstructed = linear_activation(z @ self.W_dec)\n",
    "        return z, x_reconstructed\n",
    "    \n",
    "    def backward(self, x, x_reconstructed):\n",
    "        error = x_reconstructed - x        \n",
    "        \n",
    "        dW_enc = (x.T @ error) @ self.W_dec.T\n",
    "        dW_dec = (x @ self.W_enc).T @ error               \n",
    "        \n",
    "        self.W_dec -= self.learning_rate * dW_dec\n",
    "        self.W_enc -= self.learning_rate * dW_enc        \n",
    "        \n",
    "        self.W_dec = normalize_weights(self.W_dec)\n",
    "        self.W_enc = normalize_weights(self.W_enc)\n",
    "    \n",
    "    def train(self, data, epochs=1000, max_loss: float = 100, learn_by_loss: bool = False):\n",
    "        for epoch in range(epochs):\n",
    "            total_loss = 0\n",
    "            for x in data:                \n",
    "                x = np.matrix(x)\n",
    "                _, x_reconstructed = self.forward(x)\n",
    "                self.backward(x, x_reconstructed)\n",
    "                total_loss += np.sum(np.array(x - x_reconstructed) ** 2) # Put into loop\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss}')\n",
    "            if learn_by_loss and total_loss <= max_loss:\n",
    "                break            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image compression/decompression pipeline\n",
    "def compress_image(compression_weights, img_array, channels_amount: int,\n",
    "                   block_height: int, block_width: int, overlap: float = 0):    \n",
    "    normalized = (2.0 * img_array.astype(np.float32) / MAX_RGB_VALUE) - 1.0\n",
    "    blocks = image_to_blocks(normalized, block_height, block_width, overlap)\n",
    "    blocks = blocks.reshape((len(blocks), block_height * block_width, channels_amount))\n",
    "    if channels_amount == 3:\n",
    "        blocks = blocks.transpose(0, 2, 1)    \n",
    "    blocks = np.einsum('ijk,kl->ijl', blocks, compression_weights)     \n",
    "    return blocks\n",
    "    \n",
    "\n",
    "def decompress_image(decompression_weights, compressed_img, img_shape, channels_amount: int,\n",
    "                     block_height: int, block_width: int, overlap: float = 0) -> Image.Image:\n",
    "    compressed_img = np.einsum('ijk,kl->ijl', compressed_img, decompression_weights)\n",
    "    compressed_img = MAX_RGB_VALUE * (compressed_img + 1.0) / 2.0\n",
    "    if channels_amount == 3:\n",
    "        compressed_img = compressed_img.transpose(0, 2, 1)\n",
    "    compressed_img = compressed_img.reshape((len(compressed_img), block_height, block_width, channels_amount))    \n",
    "    img_array = blocks_to_image(compressed_img, img_shape, block_height, block_width, overlap)    \n",
    "    return Image.fromarray(img_array).convert('RGB' if channels_amount == 3 else 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = 1.5470249163833032\n",
      "Epoch 1/15000, Loss: 312824.7363811969\n",
      "Epoch 2/15000, Loss: 2020.7171050139548\n",
      "Epoch 3/15000, Loss: 1610.7617967649478\n",
      "Epoch 4/15000, Loss: 1401.0536728625302\n",
      "Epoch 5/15000, Loss: 1261.6015689438786\n",
      "Epoch 6/15000, Loss: 1157.1862414353704\n",
      "Epoch 7/15000, Loss: 1074.4765604893857\n",
      "Epoch 8/15000, Loss: 1006.6358263937997\n",
      "Epoch 9/15000, Loss: 949.4398048925941\n",
      "Epoch 10/15000, Loss: 900.1133024965471\n",
      "Epoch 11/15000, Loss: 856.8076113198338\n",
      "Epoch 12/15000, Loss: 818.2753735952897\n",
      "Epoch 13/15000, Loss: 783.6531406948642\n",
      "Epoch 14/15000, Loss: 752.3201211324991\n",
      "Epoch 15/15000, Loss: 723.8097863988947\n",
      "Epoch 16/15000, Loss: 697.7559132812028\n",
      "Epoch 17/15000, Loss: 673.8600329060338\n",
      "Epoch 18/15000, Loss: 651.8717941527345\n",
      "Epoch 19/15000, Loss: 631.5769622698131\n",
      "Epoch 20/15000, Loss: 612.7898618252965\n",
      "Epoch 21/15000, Loss: 595.3483756273987\n",
      "Epoch 22/15000, Loss: 579.1104058541823\n",
      "Epoch 23/15000, Loss: 563.9511797088832\n",
      "Epoch 24/15000, Loss: 549.7610609925946\n",
      "Epoch 25/15000, Loss: 536.4436878574207\n",
      "Epoch 26/15000, Loss: 523.9143440091862\n",
      "Epoch 27/15000, Loss: 512.0985159198486\n",
      "Epoch 28/15000, Loss: 500.9306106336387\n",
      "Epoch 29/15000, Loss: 490.3528184658548\n",
      "Epoch 30/15000, Loss: 480.31410855895683\n",
      "Epoch 31/15000, Loss: 470.76934627861004\n",
      "Epoch 32/15000, Loss: 461.6785215333086\n",
      "Epoch 33/15000, Loss: 453.00607708246554\n",
      "Epoch 34/15000, Loss: 444.7203260654723\n",
      "Epoch 35/15000, Loss: 436.7929484042687\n",
      "Epoch 36/15000, Loss: 429.1985563682603\n",
      "Epoch 37/15000, Loss: 421.91432037326206\n",
      "Epoch 38/15000, Loss: 414.91964694582765\n",
      "Epoch 39/15000, Loss: 408.19590166302373\n",
      "Epoch 40/15000, Loss: 401.72617073353314\n",
      "Epoch 41/15000, Loss: 395.4950556910245\n",
      "Epoch 42/15000, Loss: 389.4884964089238\n",
      "Epoch 43/15000, Loss: 383.6936183096639\n",
      "Epoch 44/15000, Loss: 378.09860022977216\n",
      "Epoch 45/15000, Loss: 372.6925599173069\n",
      "Epoch 46/15000, Loss: 367.4654545853531\n",
      "Epoch 47/15000, Loss: 362.407994330505\n",
      "Epoch 48/15000, Loss: 357.5115665554166\n",
      "Epoch 49/15000, Loss: 352.76816981612154\n",
      "Epoch 50/15000, Loss: 348.1703557542999\n",
      "Epoch 51/15000, Loss: 343.7111779777073\n",
      "Epoch 52/15000, Loss: 339.38414692392996\n",
      "Epoch 53/15000, Loss: 335.1831898879084\n",
      "Epoch 54/15000, Loss: 331.1026155164332\n",
      "Epoch 55/15000, Loss: 327.1370821764497\n",
      "Epoch 56/15000, Loss: 323.28156969145834\n",
      "Epoch 57/15000, Loss: 319.531354014191\n",
      "Epoch 58/15000, Loss: 315.8819844661011\n",
      "Epoch 59/15000, Loss: 312.3292632269659\n",
      "Epoch 60/15000, Loss: 308.8692268024976\n",
      "Epoch 61/15000, Loss: 305.4981292356833\n",
      "Epoch 62/15000, Loss: 302.2124268595916\n",
      "Epoch 63/15000, Loss: 299.0087644166449\n",
      "Epoch 64/15000, Loss: 295.88396239252904\n",
      "Epoch 65/15000, Loss: 292.8350054326478\n",
      "Epoch 66/15000, Loss: 289.8590317259328\n",
      "Epoch 67/15000, Loss: 286.95332325525317\n",
      "Epoch 68/15000, Loss: 284.1152968261011\n",
      "Epoch 69/15000, Loss: 281.3424957958761\n",
      "Epoch 70/15000, Loss: 278.63258243532164\n",
      "Epoch 71/15000, Loss: 275.9833308616178\n",
      "Epoch 72/15000, Loss: 273.39262048955476\n",
      "Epoch 73/15000, Loss: 270.85842995322116\n",
      "Epoch 74/15000, Loss: 268.37883145585823\n",
      "Epoch 75/15000, Loss: 265.9519855101425\n",
      "Epoch 76/15000, Loss: 263.5761360351621\n",
      "Epoch 77/15000, Loss: 261.2496057798564\n",
      "Epoch 78/15000, Loss: 258.97079204585583\n",
      "Epoch 79/15000, Loss: 256.73816268532806\n",
      "Epoch 80/15000, Loss: 254.55025235191786\n",
      "Epoch 81/15000, Loss: 252.4056589850138\n",
      "Epoch 82/15000, Loss: 250.30304050943909\n",
      "Epoch 83/15000, Loss: 248.24111173443023\n",
      "Epoch 84/15000, Loss: 246.21864143722078\n",
      "Epoch 85/15000, Loss: 244.2344496179386\n",
      "Epoch 86/15000, Loss: 242.28740491370104\n",
      "Epoch 87/15000, Loss: 240.3764221608876\n",
      "Epoch 88/15000, Loss: 238.5004600955301\n",
      "Epoch 89/15000, Loss: 236.6585191826227\n",
      "Epoch 90/15000, Loss: 234.84963956592551\n",
      "Epoch 91/15000, Loss: 233.072899130545\n",
      "Epoch 92/15000, Loss: 231.32741167118982\n",
      "Epoch 93/15000, Loss: 229.6123251595563\n",
      "Epoch 94/15000, Loss: 227.92682010483261\n",
      "Epoch 95/15000, Loss: 226.27010800173903\n",
      "Epoch 96/15000, Loss: 224.64142986094308\n",
      "Epoch 97/15000, Loss: 223.04005481708003\n",
      "Epoch 98/15000, Loss: 221.4652788099221\n",
      "Epoch 99/15000, Loss: 219.91642333455678\n",
      "Epoch 100/15000, Loss: 218.39283425672178\n",
      "Epoch 101/15000, Loss: 216.89388068969583\n",
      "Epoch 102/15000, Loss: 215.41895392934356\n",
      "Epoch 103/15000, Loss: 213.96746644419773\n",
      "Epoch 104/15000, Loss: 212.53885091756334\n",
      "Epoch 105/15000, Loss: 211.13255933889053\n",
      "Epoch 106/15000, Loss: 209.7480621417703\n",
      "Epoch 107/15000, Loss: 208.38484738608028\n",
      "Epoch 108/15000, Loss: 207.04241998195647\n",
      "Epoch 109/15000, Loss: 205.72030095337354\n",
      "Epoch 110/15000, Loss: 204.4180267392548\n",
      "Epoch 111/15000, Loss: 203.1351485301394\n",
      "Epoch 112/15000, Loss: 201.8712316385433\n",
      "Epoch 113/15000, Loss: 200.62585490123644\n"
     ]
    }
   ],
   "source": [
    "# Collecting everything\n",
    "\n",
    "block_width = 10\n",
    "block_height = 10\n",
    "\n",
    "n = block_height * block_width\n",
    "# Hidden layer neuron amount\n",
    "p = 64 \n",
    "\n",
    "img = Image.open('test_cat.jpg')\n",
    "img_array = np.asarray(img)\n",
    "shape = img_array.shape\n",
    "blocks = image_to_blocks(img_array, block_height, block_width, overlap=0)\n",
    "\n",
    "l = len(blocks)\n",
    "# Compression coeff\n",
    "print('Z =', (n*l) / ((n+l) * p+2))\n",
    "\n",
    "one_color = blocks[:, : ,:, 0]\n",
    "one_color = (2 * one_color / MAX_RGB_VALUE) - 1\n",
    "one_color = one_color.reshape((len(blocks), 10 * 10))\n",
    "\n",
    "train = np.matrix(one_color[np.random.choice(one_color.shape[0], int(one_color.shape[0] * 0.2))])\n",
    "train.shape\n",
    "train[0].shape\n",
    "\n",
    "network = LRNN(100, 64, 0.001)\n",
    "network.train(train, 15000, learn_by_loss=True, max_loss=200)\n",
    "\n",
    "compressed = compress_image(network.W_enc, img_array, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg = decompress_image(network.W_dec, compressed, shape, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg_array = np.asarray(dimg)\n",
    "dimg.save('compression-decompression_test.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
