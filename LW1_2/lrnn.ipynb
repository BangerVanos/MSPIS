{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Лабораторная работа 1 по дисциплине МРЗвИС\n",
    "# Выполнена студентом группы 121702\n",
    "# БГУИР Заломов Роман Андреевич\n",
    "#\n",
    "# Вариант 15: Реализовать модель линейной рециркуляционной сети \n",
    "# с постоянным коэффициентом обучения и нормированными весовыми коэффициентами.\n",
    "#\n",
    "# 21.10.2024\n",
    "# 28.10.2024 Исправлена логика подсчёта ошибки и исправлена логика восстановления изображения из блоков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_RGB_VALUE = 255\n",
    "COLOR_CHANNELS_AMOUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_to_blocks(image, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image.shape[:2]\n",
    "\n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "\n",
    "    blocks = []\n",
    "\n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i:i+b_h, j:j+b_w]                                  \n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image[i_h-b_h:i_h, j:j+b_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image[i:i+b_h, i_w-b_w:i_w]\n",
    "            blocks.append(block)    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image[i_h-b_h:i_h, i_w-b_w:i_w]\n",
    "        blocks.append(block)\n",
    "    \n",
    "    return np.asarray(blocks)\n",
    "\n",
    "\n",
    "def blocks_to_image(image_blocks, image_shape, b_h, b_w, overlap = 0):\n",
    "    i_h, i_w = image_shape[:2]\n",
    "    c = image_shape[2] if len(image_shape) == 3 else 1\n",
    "\n",
    "    restored_image = np.zeros((i_h, i_w, c), dtype=np.float64)\n",
    "    count_matrix = np.zeros((i_h, i_w), dtype=np.float64)\n",
    "    \n",
    "    step_h = int(b_h * (1 - overlap))\n",
    "    step_w = int(b_w * (1 - overlap))\n",
    "    \n",
    "    block_index = 0\n",
    "    \n",
    "    for i in range(0, i_h - b_h + 1, step_h):\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]            \n",
    "            restored_image[i:i+b_h, j:j+b_w] += block\n",
    "            count_matrix[i:i+b_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0:\n",
    "        for j in range(0, i_w - b_w + 1, step_w):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i_h-b_h:i_h, j:j+b_w] += block\n",
    "            count_matrix[i_h-b_h:i_h, j:j+b_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_w % b_w != 0:\n",
    "        for i in range(0, i_h - b_h + 1, step_h):\n",
    "            block = image_blocks[block_index]\n",
    "            restored_image[i:i+b_h, i_w-b_w:i_w] += block\n",
    "            count_matrix[i:i+b_h, i_w-b_w:i_w] += 1\n",
    "            block_index += 1    \n",
    "    \n",
    "    if i_h % b_h != 0 and i_w % b_w != 0:\n",
    "        block = image_blocks[block_index]\n",
    "        restored_image[i_h-b_h:i_h, i_w-b_w:i_w] += block\n",
    "        count_matrix[i_h-b_h:i_h, i_w-b_w:i_w] += 1    \n",
    "    \n",
    "    count_matrix[count_matrix == 0] = 1    \n",
    "    restored_image = restored_image / count_matrix[..., np.newaxis]\n",
    "    restored_image[restored_image > 255] = 255    \n",
    "    \n",
    "    return restored_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_weights(weights):\n",
    "    norms = np.linalg.norm(weights, axis=0)\n",
    "    return weights / norms\n",
    "\n",
    "# Функция активации\n",
    "def linear_activation(x):\n",
    "    return x\n",
    "\n",
    "class LRNN:\n",
    "    def __init__(self, input_dim, latent_dim, learning_rate=0.001):        \n",
    "        self.input_dim = input_dim\n",
    "        self.latent_dim = latent_dim\n",
    "        self.learning_rate = learning_rate        \n",
    "        \n",
    "        self.W_enc = normalize_weights(np.random.rand(self.input_dim, self.latent_dim))\n",
    "        self.W_dec = normalize_weights(np.random.rand(self.latent_dim, self.input_dim))        \n",
    "\n",
    "        self.epoch: int = 0\n",
    "    \n",
    "    def forward(self, x):\n",
    "        z = linear_activation(x @ self.W_enc)\n",
    "        x_reconstructed = linear_activation(z @ self.W_dec)\n",
    "        return z, x_reconstructed\n",
    "    \n",
    "    def backward(self, x, x_reconstructed):\n",
    "        error = x_reconstructed - x        \n",
    "        \n",
    "        dW_enc = (x.T @ error) @ self.W_dec.T\n",
    "        dW_dec = (x @ self.W_enc).T @ error               \n",
    "        \n",
    "        self.W_dec -= self.learning_rate * dW_dec\n",
    "        self.W_enc -= self.learning_rate * dW_enc        \n",
    "        \n",
    "        self.W_dec = normalize_weights(self.W_dec)\n",
    "        self.W_enc = normalize_weights(self.W_enc)\n",
    "    \n",
    "    def squared_error(self, y_true, y_predicted) -> float:\n",
    "        error = 0\n",
    "        y_true, y_predicted = np.array(y_true)[0], np.array(y_predicted)[0]\n",
    "        if len(y_true) != len(y_predicted):\n",
    "            raise ValueError('True and predicted vectors must be same size!')\n",
    "        for i in range(len(y_true)):\n",
    "            error += (y_true[i] - y_predicted[i]) ** 2\n",
    "        return error\n",
    "    \n",
    "    def train(self, data, epochs=1000, max_loss: float = 100, learn_by_loss: bool = False):\n",
    "        for epoch in range(epochs):\n",
    "            self.epoch += 1\n",
    "            total_loss = 0\n",
    "            for x in data:                \n",
    "                x = np.matrix(x)\n",
    "                _, x_reconstructed = self.forward(x)\n",
    "                self.backward(x, x_reconstructed)\n",
    "            for x in data:\n",
    "                _, x_reconstructed = self.forward(x)\n",
    "                total_loss += self.squared_error(x, x_reconstructed)\n",
    "            print(f'Epoch {epoch+1}/{epochs}, Loss: {total_loss}')            \n",
    "            if learn_by_loss and total_loss <= max_loss:\n",
    "                break            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image compression/decompression pipeline\n",
    "def compress_image(compression_weights, img_array, channels_amount: int,\n",
    "                   block_height: int, block_width: int, overlap: float = 0):    \n",
    "    normalized = (2.0 * img_array.astype(np.float32) / MAX_RGB_VALUE) - 1.0\n",
    "    blocks = image_to_blocks(normalized, block_height, block_width, overlap)\n",
    "    blocks = blocks.reshape((len(blocks), block_height * block_width, channels_amount))\n",
    "    if channels_amount == 3:\n",
    "        blocks = blocks.transpose(0, 2, 1)    \n",
    "    blocks = np.einsum('ijk,kl->ijl', blocks, compression_weights)     \n",
    "    return blocks\n",
    "    \n",
    "\n",
    "def decompress_image(decompression_weights, compressed_img, img_shape, channels_amount: int,\n",
    "                     block_height: int, block_width: int, overlap: float = 0) -> Image.Image:\n",
    "    compressed_img = np.einsum('ijk,kl->ijl', compressed_img, decompression_weights)\n",
    "    compressed_img = MAX_RGB_VALUE * (compressed_img + 1.0) / 2.0\n",
    "    if channels_amount == 3:\n",
    "        compressed_img = compressed_img.transpose(0, 2, 1)\n",
    "    compressed_img = compressed_img.reshape((len(compressed_img), block_height, block_width, channels_amount))    \n",
    "    img_array = blocks_to_image(compressed_img, img_shape, block_height, block_width, overlap)    \n",
    "    return Image.fromarray(img_array).convert('RGB' if channels_amount == 3 else 'L')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Z = 1.5492138377310074\n",
      "float64\n",
      "Epoch 1/15000, Loss: 6004.547855722703\n",
      "Epoch 2/15000, Loss: 5129.0333440928725\n",
      "Epoch 3/15000, Loss: 4524.484768690819\n",
      "Epoch 4/15000, Loss: 4071.706444716186\n",
      "Epoch 5/15000, Loss: 3716.5241190386864\n",
      "Epoch 6/15000, Loss: 3429.178326785791\n",
      "Epoch 7/15000, Loss: 3191.3037297958604\n",
      "Epoch 8/15000, Loss: 2990.6556826822707\n",
      "Epoch 9/15000, Loss: 2818.6616104941045\n",
      "Epoch 10/15000, Loss: 2669.159430933969\n",
      "Epoch 11/15000, Loss: 2537.669776135855\n",
      "Epoch 12/15000, Loss: 2420.9201772888905\n",
      "Epoch 13/15000, Loss: 2316.5003427892734\n",
      "Epoch 14/15000, Loss: 2222.6004609543506\n",
      "Epoch 15/15000, Loss: 2137.815284624784\n",
      "Epoch 16/15000, Loss: 2061.0062200469615\n",
      "Epoch 17/15000, Loss: 1991.2129818394558\n",
      "Epoch 18/15000, Loss: 1927.603056648343\n",
      "Epoch 19/15000, Loss: 1869.4457484119087\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 24\u001b[0m\n\u001b[0;32m     20\u001b[0m train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatrix(color_df[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(color_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28mint\u001b[39m(color_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.05\u001b[39m))])\n\u001b[0;32m     23\u001b[0m network \u001b[38;5;241m=\u001b[39m LRNN(\u001b[38;5;241m100\u001b[39m, \u001b[38;5;241m64\u001b[39m, \u001b[38;5;241m0.001\u001b[39m)\n\u001b[1;32m---> 24\u001b[0m \u001b[43mnetwork\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearn_by_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_loss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1200\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m compressed \u001b[38;5;241m=\u001b[39m compress_image(network\u001b[38;5;241m.\u001b[39mW_enc, img_array, COLOR_CHANNELS_AMOUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m dimg \u001b[38;5;241m=\u001b[39m decompress_image(network\u001b[38;5;241m.\u001b[39mW_dec, compressed, shape, COLOR_CHANNELS_AMOUNT, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 55\u001b[0m, in \u001b[0;36mLRNN.train\u001b[1;34m(self, data, epochs, max_loss, learn_by_loss)\u001b[0m\n\u001b[0;32m     53\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmatrix(x)\n\u001b[0;32m     54\u001b[0m     _, x_reconstructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_reconstructed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m     57\u001b[0m     _, x_reconstructed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(x)\n",
      "Cell \u001b[1;32mIn[13], line 30\u001b[0m, in \u001b[0;36mLRNN.backward\u001b[1;34m(self, x, x_reconstructed)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, x_reconstructed):\n\u001b[0;32m     28\u001b[0m     error \u001b[38;5;241m=\u001b[39m x_reconstructed \u001b[38;5;241m-\u001b[39m x        \n\u001b[1;32m---> 30\u001b[0m     dW_enc \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_dec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\n\u001b[0;32m     31\u001b[0m     dW_dec \u001b[38;5;241m=\u001b[39m (x \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_enc)\u001b[38;5;241m.\u001b[39mT \u001b[38;5;241m@\u001b[39m error               \n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mW_dec \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlearning_rate \u001b[38;5;241m*\u001b[39m dW_dec\n",
      "File \u001b[1;32md:\\Programs\\Programming\\BSUIR\\MSPIS\\LW1_2\\.venv\\Lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:170\u001b[0m, in \u001b[0;36mmatrix.__array_finalize__\u001b[1;34m(self, obj)\u001b[0m\n\u001b[0;32m    165\u001b[0m     ret \u001b[38;5;241m=\u001b[39m N\u001b[38;5;241m.\u001b[39mndarray\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(subtype, shape, arr\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m    166\u001b[0m                             buffer\u001b[38;5;241m=\u001b[39marr,\n\u001b[0;32m    167\u001b[0m                             order\u001b[38;5;241m=\u001b[39morder)\n\u001b[0;32m    168\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n\u001b[1;32m--> 170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__array_finalize__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[0;32m    171\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(obj, matrix) \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_getitem): \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Collecting everything\n",
    "\n",
    "block_width = 10\n",
    "block_height = 10\n",
    "\n",
    "n = block_height * block_width\n",
    "# Hidden layer neuron amount\n",
    "p = 64 \n",
    "\n",
    "img = Image.open('mountains.jpg')\n",
    "img_array = np.asarray(img)\n",
    "shape = img_array.shape\n",
    "blocks = image_to_blocks(img_array, block_height, block_width, overlap=0)\n",
    "\n",
    "l = len(blocks)\n",
    "# Compression coeff\n",
    "print('Z =', (n*l) / ((n+l) * p+2))\n",
    "\n",
    "color_df = ((2 * blocks / MAX_RGB_VALUE) - 1).reshape(len(blocks), -1, 3).transpose(0, 2, 1).reshape(-1, 10 * 10)\n",
    "train = np.matrix(color_df[np.random.choice(color_df.shape[0], int(color_df.shape[0] * 0.05))])\n",
    "\n",
    "\n",
    "network = LRNN(100, 64, 0.001)\n",
    "network.train(train, 15000, learn_by_loss=True, max_loss=1200)\n",
    "\n",
    "compressed = compress_image(network.W_enc, img_array, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg = decompress_image(network.W_dec, compressed, shape, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg_array = np.asarray(dimg)\n",
    "dimg.save('compression-decompression_test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test on another pic\n",
    "img = Image.open('test5.jpg')\n",
    "img_array = np.asarray(img)\n",
    "shape = img_array.shape\n",
    "compressed = compress_image(network.W_enc, img_array, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg = decompress_image(network.W_dec, compressed, shape, COLOR_CHANNELS_AMOUNT, 10, 10, 0)\n",
    "dimg_array = np.asarray(dimg)\n",
    "dimg.save('compression-decompression_test.jpg')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
